
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Debugging &#8212; ploomber 0.19.6 documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom-theme.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/mermaid-style.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/mermaid-layout.css" />
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../_static/js/custom.js"></script>
    <script src="../_static/js/mermaid.min.js"></script>
    <script src="../_static/js/terminal.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Versioning" href="versioning.html" />
    <link rel="prev" title="Pipeline testing" href="testing.html" />
 

<!-- Required meta tags -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<!-- Bootstrap CSS -->
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css"
    integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">

<style>
    body {
        padding-top: 5rem;
    }

    /* make all images responsive (same as .img-fluid) */
    img {
        max-width: 100%;
        height: auto;
    }
</style>

<!-- Algolia -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@docsearch/css@3" />
</pre>
</link>

<!-- Below script for subscribe button in videos page-->
<script src="https://apis.google.com/js/platform.js"></script>
<!-- Optional JavaScript -->
<!-- jQuery first, then Popper.js, then Bootstrap JS -->
<!-- jQuery is loaded by sphinx anyway -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js"
    integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1"
    crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js"
    integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM"
    crossorigin="anonymous"></script>




  </head><body>



<nav class="navbar navbar-expand-md navbar-dark fixed-top">
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#first-column"
        aria-controls="first-column" aria-expanded="false" aria-label="Toggle TOC">
        <span class="navbar-toggler-icon"></span>
    </button>

    <a class="navbar-brand" href="../index.html">Ploomber</a>

    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#top-bar" aria-controls="top-bar"
        aria-expanded="false" aria-label="Toggle navigation">
        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="currentColor" class="bi bi-search"
            viewBox="0 0 16 16">
            <path
                d="M11.742 10.344a6.5 6.5 0 1 0-1.397 1.398h-.001c.03.04.062.078.098.115l3.85 3.85a1 1 0 0 0 1.415-1.414l-3.85-3.85a1.007 1.007 0 0 0-.115-.1zM12 6.5a5.5 5.5 0 1 1-11 0 5.5 5.5 0 0 1 11 0z" />
        </svg>
    </button>

    <div class="collapse navbar-collapse" id="top-bar">
        <ul class="navbar-nav mr-auto">
            <li class="nav-item  active ">
                <a class="nav-link" href="../index.html">Documentation
                </a>
            </li>
            <li class="nav-item ">
                <a class="nav-link" href="../cloud/cloud-execution.html">Cloud
                </a>
            </li>
            <li class="nav-item ">
                <a class="nav-link" href="../videos.html">Videos</a>
            </li>
            <li class="nav-item">
                <a class="nav-link" href="https://github.com/ploomber/ploomber">GitHub</a>
            </li>
            <li class="nav-item">
                <a class="nav-link" href="https://ploomber.io/community">Community</a>
            </li>
            <li class="nav-item">
                <a class="nav-link" href="https://www.getrevue.co/profile/ploomber">Newsletter</a>
            </li>
            <li class="nav-item">
                <a class="nav-link" href="https://ploomber.io">Blog</a>
            </li>
        </ul>

        <!-- By default any child element that uses Bootstrap nav class falls under display flex! -->
        <div class="flex-md-shrink-0" id="search">
            <!-- flex-md-shrink-0 is a responsive class inside boostrap flex class that shrinks elements as the width decreases!-->
            <form class="search form-inline my-2 my-lg-0" action="../search.html" method="get">
                <input class="form-control mr-sm-2" type="text" placeholder="Search" aria-label="Search" name="q">
                <button class="btn btn-secondary my-2 my-sm-0" type="submit">Search</button>
            </form>
        </div>

    </div>
</nav>



<div class="container-fluid">
    <div class="row">
        <div class="col-md-3 col-xl-2 first-column collapse" id="first-column">
            

<div class="global-toc"><ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../get-started/index.html">Get Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use-cases/index.html">Use Cases</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">User Guide</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="templates.html">Downloading templates</a></li>
<li class="toctree-l2"><a class="reference internal" href="cli.html">Command-line interface</a></li>
<li class="toctree-l2"><a class="reference internal" href="jupyter.html">Jupyter integration</a></li>
<li class="toctree-l2"><a class="reference internal" href="scaffold.html">Scaffolding projects</a></li>
<li class="toctree-l2"><a class="reference internal" href="refactoring.html">Refactoring legacy notebooks</a></li>
<li class="toctree-l2"><a class="reference internal" href="parametrized.html">Parametrized pipelines</a></li>
<li class="toctree-l2"><a class="reference internal" href="configuration.html">Configuration (<code class="docutils literal notranslate"><span class="pre">dev</span></code>/<code class="docutils literal notranslate"><span class="pre">prod</span></code>)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../get-started/sql-pipeline.html">SQL Pipelines</a></li>
<li class="toctree-l2"><a class="reference internal" href="sql-templating.html">SQL templating</a></li>
<li class="toctree-l2"><a class="reference internal" href="testing.html">Pipeline testing</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Debugging</a></li>
<li class="toctree-l2"><a class="reference internal" href="versioning.html">Versioning</a></li>
<li class="toctree-l2"><a class="reference internal" href="logging.html">Logging</a></li>
<li class="toctree-l2"><a class="reference internal" href="serialization.html">Serialization</a></li>
<li class="toctree-l2"><a class="reference internal" href="shell.html">Shell tasks</a></li>
<li class="toctree-l2"><a class="reference internal" href="editors.html">Other editors (VSCode, PyCharm, etc.)</a></li>
<li class="toctree-l2"><a class="reference internal" href="r-support.html">R support</a></li>
<li class="toctree-l2"><a class="reference internal" href="faq_index.html">FAQ and Glossary</a></li>
<li class="toctree-l2"><a class="reference internal" href="spec-vs-python.html">Spec API vs. Python API</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../cloud/index.html">Cloud</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deployment/index.html">Deployment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cookbook/index.html">Cookbook</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/index.html">API Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../community/index.html">Community</a></li>
</ul>
</div>

            <div class="help-tooltip">
                <p>Something not working? <a
                        href="https://github.com/ploomber/ploomber/issues/new?body=Documentation+page%3A+user-guide%2Fdebugging"
                        target="_blank" rel="noreferrer">Open an issue on
                        GitHub</a> or <a href="https://ploomber.io/community" target="_blank" rel="noreferrer">message
                        us on Slack.</a></p>
            </div>
        </div>
        <div class="col-md-9 col-xl-8">
            <div class="document">
                <div class="documentwrapper">
                    <div class="bodywrapper">
                        <div class="body" role="main">
                            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt .copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
.jp-RenderedHTMLCommon table,
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
.jp-RenderedHTMLCommon thead,
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
.jp-RenderedHTMLCommon tr,
.jp-RenderedHTMLCommon th,
.jp-RenderedHTMLCommon td,
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
.jp-RenderedHTMLCommon th,
div.rendered_html th {
  font-weight: bold;
}
.jp-RenderedHTMLCommon tbody tr:nth-child(odd),
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
.jp-RenderedHTMLCommon tbody tr:hover,
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}
</style>
<style>
    div.nbinput.container div.input_area {
        background: black;
    }
</style>

<script src="../_static/js/nbsphinx.js"></script><p>To run this example locally, <a class="reference external" href="https://docs.ploomber.io/en/latest/get-started/quick-start.html">install Ploomber</a> and execute: <code class="docutils literal notranslate"><span class="pre">ploomber</span> <span class="pre">examples</span> <span class="pre">-n</span> <span class="pre">guides/debugging</span></code></p>
<p>To start a free, hosted JupyterLab: <a class="reference external" href="https://mybinder.org/v2/gh/ploomber/binder-env/main?urlpath=git-pull%3Frepo%3Dhttps%253A%252F%252Fgithub.com%252Fploomber%252Fprojects%26urlpath%3Dlab%252Ftree%252Fprojects%252Fguides/debugging%252FREADME.ipynb%26branch%3Dmaster"><img alt="binder-logo" src="https://mybinder.org/badge_logo.svg" /></a></p>
<p>Found an issue? <a class="reference external" href="https://github.com/ploomber/projects/issues/new?title=guides/debugging%20issue">Let us know.</a></p>
<p>Have questions? <a class="reference external" href="https://ploomber.io/community/">Ask us anything on Slack.</a></p>
<section id="Debugging">
<h1>Debugging<a class="headerlink" href="#Debugging" title="Permalink to this headline">¶</a></h1>
<!-- start description --><p>Tutorial showing techniques for debugging pipelines.</p>
<p><em>For a quick reference,</em> <a class="reference external" href="https://docs.ploomber.io/en/latest/cookbook/debugging.html">click here</a>.</p>
<section id="Why-debugging-pipelines-is-hard">
<h2>Why debugging pipelines is hard<a class="headerlink" href="#Why-debugging-pipelines-is-hard" title="Permalink to this headline">¶</a></h2>
<p>Debugging data pipelines is hard because there are three factors involved:</p>
<ol class="arabic simple">
<li><p>Our code</p></li>
<li><p>Parameters</p></li>
<li><p>Input data</p></li>
</ol>
<p>In simple cases, pipeline error messages might give us enough information to fix the bug, but in other (which happen more often), we have to inspect the program while running to understand what’s going on: see variable values, run a few diagnostic commands, etc.</p>
<p>Inspecting our program requires us to re-execute it under the same conditions to replicate the crash. Replicating conditions means having the same code, parameters and input data.</p>
<p>Getting the same code is easy if we know the version (i.e., git hash) running during the crash. Replicating parameters involves more work; one way to approach this is to ensure we always log parameters at the start of every pipeline execution.</p>
<p>Input data is more complex than it sounds. When our project is not properly assembled as a data pipeline, we might run into issues if we use an incorrect file as input (e.g. reading <code class="docutils literal notranslate"><span class="pre">/data/some-file.csv</span></code> instead of <code class="docutils literal notranslate"><span class="pre">/data/file.csv</span></code>). That’s why Ploomber puts a lot of emphasis on declaring products once and automatically propagating them to any downstream consumers, to ensure that there is a single source of truth and we always read if the appropriate file or SQL table from the upstream task.</p>
<p>As you can see, replicating error conditions accurately involves some work from your end: 1) recording the project version and 2) input parameters (on every run) and 3) know which input data led to the crash. Once you have these three pieces of information, Ploomber will provide you tools to catch those sneaky bugs.</p>
</section>
<section id="Debugger-basics">
<h2>Debugger basics<a class="headerlink" href="#Debugger-basics" title="Permalink to this headline">¶</a></h2>
<p>A debugger is a program that helps inspect another program for debugging. Python comes with a debugger called <a class="reference external" href="https://docs.python.org/3/library/pdb.html">pdb</a>.</p>
<p>There are a few approaches for debugging programs. One approach is line-by-line debugging, which starts our program in <em>debug</em> mode so we can easily inspect variables, move to the next line, etc.</p>
<p>One important concept to know when debugging is <em>stack frame</em>. Simply speaking, stack frames represent the state of our code at a given level. When you write a non-trivial function, it will depend on other functions to work (yours or from third party packages). Each function has its own stack frame which defines the variables that are available to it.</p>
<p>When a program fails, it can do so at different levels (i.e. a different stack frame). Let’s see a simple example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">reciprocal</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="mi">1</span><span class="o">/</span><span class="n">x</span>

<span class="k">def</span> <span class="nf">reciprocal_and_multiply</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">reciprocal</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">*</span> <span class="n">y</span>
</pre></div>
</div>
<p>There are two places where things can go wrong in the program above: if we pass <code class="docutils literal notranslate"><span class="pre">x=0</span></code>, the <code class="docutils literal notranslate"><span class="pre">reciprocal</span></code> operation will fail. If we pass <code class="docutils literal notranslate"><span class="pre">y=None</span></code>, the program fails, but it will do so in the <code class="docutils literal notranslate"><span class="pre">reciprocal_and_multiply</span></code> function. For this trivial example, it’s easy to see at which level the code breaks but in a real program the source code alone is usually not enough to know. Moving between stack frames can help you find out where the error is coming from.</p>
</section>
<section id="Tales-of-a-buggy-pipeline">
<h2>Tales of a buggy pipeline<a class="headerlink" href="#Tales-of-a-buggy-pipeline" title="Permalink to this headline">¶</a></h2>
<p>Let’s take a look at our example pipeline declaration:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="c1"># Content of pipeline.yaml</span><span class="w"></span>
<span class="nt">tasks</span><span class="p">:</span><span class="w"></span>
<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">source</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">load.py</span><span class="w"></span>
<span class="w">    </span><span class="nt">product</span><span class="p">:</span><span class="w"></span>
<span class="w">      </span><span class="nt">nb</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">output/raw.html</span><span class="w"></span>
<span class="w">      </span><span class="nt">train</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">output/train.csv</span><span class="w"></span>
<span class="w">      </span><span class="nt">test</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">output/test.csv</span><span class="w"></span>

<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">source</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">preprocess.py</span><span class="w"></span>
<span class="w">    </span><span class="nt">product</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">output/clean.html</span><span class="w"></span>
</pre></div>
</div>
<p>Very simple, two tasks. One loads the data and the next one preprocess it.</p>
<p>Let’s run it (don’t be scared by the long error message, scroll until the end to see the explanation):</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-sh notranslate"><div class="highlight"><pre><span></span>%%sh --no-raise-error
ploomber build --force
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Loading pipeline...
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Building task &#39;load&#39;:   0%|          | 0/2 [00:00&lt;?, ?it/s]
Executing:   0%|          | 0/5 [00:00&lt;?, ?cell/s]
Executing: 100%|██████████| 5/5 [00:01&lt;00:00,  2.85cell/s]
Building task &#39;preprocess&#39;:  50%|█████     | 1/2 [00:02&lt;00:02,  2.24s/it]
Executing:   0%|          | 0/6 [00:00&lt;?, ?cell/s]
Executing:  17%|█▋        | 1/6 [00:03&lt;00:18,  3.66s/cell]
Executing: 100%|██████████| 6/6 [00:04&lt;00:00,  1.41cell/s]
Building task &#39;preprocess&#39;: 100%|██████████| 2/2 [00:06&lt;00:00,  3.26s/it]

=============================== DAG build failed ===============================
----------- NotebookRunner: preprocess -&gt; File(&#39;output/clean.html&#39;) ------------
------------- /workspaces/projects/guides/debugging/preprocess.py --------------

---------------------------------------------------------------------------
Exception encountered at &#34;In [6]&#34;:
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
/tmp/ipykernel_7551/1567702903.py in &lt;cell line: 1&gt;()
----&gt; 1 my_preprocessing_function(X_train, X_test)

/tmp/ipykernel_7551/2058553394.py in my_preprocessing_function(X_train, X_test)
      2     encoder = OneHotEncoder()
      3     X_train_t = encoder.fit_transform(X_train)
----&gt; 4     X_test_t = encoder.transform(X_test)
      5     return X_train_t, X_test_t

/workspaces/projects/venv/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py in transform(self, X)
    880             &#34;infrequent_if_exist&#34;,
    881         }
--&gt; 882         X_int, X_mask = self._transform(
    883             X,
    884             handle_unknown=self.handle_unknown,

/workspaces/projects/venv/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py in _transform(self, X, handle_unknown, force_all_finite, warn_on_unknown)
    158                         &#34; during transform&#34;.format(diff, i)
    159                     )
--&gt; 160                     raise ValueError(msg)
    161                 else:
    162                     if warn_on_unknown:

ValueError: Found unknown categories [&#39;d&#39;] in column 0 during transform

ploomber.exceptions.TaskBuildError: Error when executing task &#39;preprocess&#39;. Partially executed notebook available at /workspaces/projects/guides/debugging/output/clean.html
ploomber.exceptions.TaskBuildError: Error building task &#34;preprocess&#34;
=============================== Summary (1 task) ===============================
NotebookRunner: preprocess -&gt; File(&#39;output/clean.html&#39;)
=============================== DAG build failed ===============================

Need help? https://ploomber.io/community
</pre></div></div>
</div>
<p>If you followed the previous tutorial, you are already familiar with Ploomber’s structured error messages. So let’s see the messages to understand what’s going on.</p>
<p>The summary tells us the following</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>=============================== Summary (1 task) ===============================
NotebookRunner: preprocess -&gt; File(&#39;output/clean.html&#39;)
=============================== DAG build failed ===============================
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">preprocess</span></code> task failed. Go up a few lines:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>ploomber.exceptions.TaskBuildError: An error occurred when calling papermil.execute_notebook, partially executed notebook with traceback available at ...
</pre></div>
</div>
<p>That’s useful, it tells us where we can find the partially executed notebook in case we want to take a look at it. A few lines up:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>ValueError: Found unknown categories [&#39;d&#39;] in column 1 during transform
</pre></div>
</div>
<p>That’s the exact line that failed, if you take a look at the original error traceback, you’ll see that the actual line that raised the exception comes from the scikit-learn library (<code class="docutils literal notranslate"><span class="pre">_encoders.py</span></code> file):</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>~/miniconda3/envs/ploomber/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py in _transform(self, X, handle_unknown)
    122                     msg = (&quot;Found unknown categories {0} in column {1}&quot;
    123                            &quot; during transform&quot;.format(diff, i))
--&gt; 124                     raise ValueError(msg)
    125                 else:
    126                     # Set the problematic rows to an acceptable value and

ValueError: Found unknown categories [&#39;d&#39;] in column 0 during transform
</pre></div>
</div>
<p>The error message provides us a lot of information: Our pipeline failed while executing task <code class="docutils literal notranslate"><span class="pre">preprocess</span></code>. Somewhere in our task’s code we ran something that made scikit-learn crash.</p>
<p>Let’s take a look at the failing task’s source code:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Content of preprocess.py</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">OneHotEncoder</span>

<span class="c1"># + tags=[&quot;parameters&quot;]</span>
<span class="n">upstream</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;load&#39;</span><span class="p">]</span>
<span class="n">product</span> <span class="o">=</span> <span class="kc">None</span>

<span class="c1"># -</span>


<span class="c1"># +</span>
<span class="k">def</span> <span class="nf">my_preprocessing_function</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">):</span>
    <span class="n">encoder</span> <span class="o">=</span> <span class="n">OneHotEncoder</span><span class="p">()</span>
    <span class="n">X_train_t</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
    <span class="n">X_test_t</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">X_train_t</span><span class="p">,</span> <span class="n">X_test_t</span>


<span class="c1"># +</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">upstream</span><span class="p">[</span><span class="s1">&#39;load&#39;</span><span class="p">][</span><span class="s1">&#39;train&#39;</span><span class="p">])</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">upstream</span><span class="p">[</span><span class="s1">&#39;load&#39;</span><span class="p">][</span><span class="s1">&#39;test&#39;</span><span class="p">])</span>

<span class="c1"># +</span>
<span class="n">my_preprocessing_function</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">)</span>
</pre></div>
</div>
<p>Our <code class="docutils literal notranslate"><span class="pre">preprocess.py</span></code> script is using scikit-learn’s <code class="docutils literal notranslate"><span class="pre">OneHotEncoder</span></code> to transform variables. The error message offers some information but not enough to fix the issue (<em>we don’t have a column named “0”!</em>). There must be something going on internally.</p>
<p>This is a good use case for Ploomber’s debugging capabilities.</p>
</section>
<section id="Starting-line-by-line-debugging-sessions">
<h2>Starting line-by-line debugging sessions<a class="headerlink" href="#Starting-line-by-line-debugging-sessions" title="Permalink to this headline">¶</a></h2>
<p>To start a debugging session you first have to start an interactive session. To do so, run the following command in the terminal:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">ploomber interact</span>
</pre></div>
</div>
<p>When it finishes setting things up, your pipeline will be available in the <code class="docutils literal notranslate"><span class="pre">dag</span></code> variable. This is a standard Python session, you can execute any Python code you want.</p>
<p>We already know that the error is happening in the <code class="docutils literal notranslate"><span class="pre">preprocess</span></code> task, you can start a line-by-line debugging session with the following command:</p>
<div class="highlight-pycon notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">dag</span><span class="p">[</span><span class="s1">&#39;preprocess&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">debug</span><span class="p">()</span>
</pre></div>
</div>
<p>Here’s a replay of my debugging session (with comments):</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span># COMMENT: I entered the command &quot;next&quot; a few times until I reached the failing line
ipdb&gt;
&gt; /var/folders/3h/_lvh_w_x5g30rrjzb_xnn2j80000gq/T/tmpbatitar6.py(45)&lt;module&gt;()
     41 X_train = pd.read_csv(upstream[&#39;load&#39;][&#39;train&#39;])
     42 X_test = pd.read_csv(upstream[&#39;load&#39;][&#39;test&#39;])
     43
     44 # + tags=[]
# COMMENT: &quot;---&gt;&quot; means that line will be executed when I send the &quot;next&quot; command
---&gt; 45 my_preprocessing_function(X_train, X_test)

ipdb&gt;
# COMMENT: Same error message that we got before!
ValueError: Found unknown categories [&#39;d&#39;] in column 0 during transform
&gt; /var/folders/3h/_lvh_w_x5g30rrjzb_xnn2j80000gq/T/tmpbatitar6.py(45)&lt;module&gt;()
     41 X_train = pd.read_csv(upstream[&#39;load&#39;][&#39;train&#39;])
     42 X_test = pd.read_csv(upstream[&#39;load&#39;][&#39;test&#39;])
     43
     44 # + tags=[]
---&gt; 45 my_preprocessing_function(X_train, X_test)
# COMMENT: I entered the &quot;down&quot; command to move one stack frame down (inside my_preprocessing_function)
ipdb&gt; down
&gt; /var/folders/3h/_lvh_w_x5g30rrjzb_xnn2j80000gq/T/tmpbatitar6.py(36)my_preprocessing_function()
     34     encoder = OneHotEncoder()
     35     X_train_t = encoder.fit_transform(X_train)
# COMMENT: The line that raised the exception
---&gt; 36     X_test_t = encoder.transform(X_test)
     37     return X_train_t, X_test_t
     38

# COMMENT: Print X_train and X_test
ipdb&gt; X_train
  cat
0   a
1   b
2   c
ipdb&gt; X_test
  cat
0   a
1   b
2   d
# COMMENT: Exit debugger with the &quot;quit&quot; command
ipdb&gt; quit
</pre></div>
</div>
<p>Ah-ha! The encoder is fitted with a column with values <code class="docutils literal notranslate"><span class="pre">a</span></code>, <code class="docutils literal notranslate"><span class="pre">b</span></code> and <code class="docutils literal notranslate"><span class="pre">c</span></code> but then applied to a testing set with value <code class="docutils literal notranslate"><span class="pre">d</span></code>. That’s why it’s breaking.</p>
<p>This is an example of how your code could be doing everything right, but your data is incompatible. How you fix this is up to us. The important thing is that we know why things are failing.</p>
</section>
<section id="Post-mortem-debugging">
<h2>Post-mortem debugging<a class="headerlink" href="#Post-mortem-debugging" title="Permalink to this headline">¶</a></h2>
<p>Line-by-line debugging puts us at the beginning of the script and then we move as we want. An alternative approach is to let the program run and start the debugging session as soon as it finds an exception, this is called <em>post-mortem</em> debugging. Starting a post-mortem session is similar: start and interactive session but then pass <code class="docutils literal notranslate"><span class="pre">kind='pm'</span></code> (<code class="docutils literal notranslate"><span class="pre">pm</span></code> stands for post-mortem) as argument to the <code class="docutils literal notranslate"><span class="pre">.debug()</span></code> function:</p>
<div class="highlight-pycon notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">dag</span><span class="p">[</span><span class="s1">&#39;preprocess&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">&#39;pm&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>Here’s the (commented) replay of my post-mortem debugging session:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span># COMMENT: I deleted a few lines for brevity
ValueError: Found unknown categories [&#39;d&#39;] in column 0 during transform
&gt; /Users/Edu/miniconda3/envs/ploomber/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py(124)_transform()
    122                     msg = (&quot;Found unknown categories {0} in column {1}&quot;
    123                            &quot; during transform&quot;.format(diff, i))
# COMMENT: The session starts here. Not very useful because we are inside the scikit-learn package
# (note the file path: site-packages/sklearn/preprocessing/_encoders.py)
--&gt; 124                     raise ValueError(msg)
    125                 else:
    126                     # Set the problematic rows to an acceptable value and
# COMMENT: Let&#39;s move up
ipdb&gt; up
&gt; /Users/Edu/miniconda3/envs/ploomber/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py(428)transform()
    426         check_is_fitted(self)
    427         # validation of X happens in _check_X called by _transform
--&gt; 428         X_int, X_mask = self._transform(X, handle_unknown=self.handle_unknown)
    429
    430         n_samples, n_features = X_int.shape
# COMMENT: Still inside scikit-learn, let&#39;s move up again
ipdb&gt; up
&gt; /var/folders/3h/_lvh_w_x5g30rrjzb_xnn2j80000gq/T/tmp653y199s.py(36)my_preprocessing_function()
     34     encoder = OneHotEncoder()
     35     X_train_t = encoder.fit_transform(X_train)
# COMMENT: Now are are in our task&#39;s code, same place as in the previous example
---&gt; 36     X_test_t = encoder.transform(X_test)
     37     return X_train_t, X_test_t
     38
ipdb&gt; X_train
  cat
0   a
1   b
2   c
ipdb&gt; X_test
  cat
0   a
1   b
2   d
ipdb&gt; quit
</pre></div>
</div>
<p>As you can see, we can use either of these two approaches.</p>
</section>
<section id="More-difficult-scenario:-no-exceptions-raised-but-wrong-output">
<h2>More difficult scenario: no exceptions raised but wrong output<a class="headerlink" href="#More-difficult-scenario:-no-exceptions-raised-but-wrong-output" title="Permalink to this headline">¶</a></h2>
<p>The previous example showed how we could debug a program that raises an exception. A more difficult scenario is when our program runs without errors but we find issues in the output (e.g. charts are not displaying correctly, data file has NAs, etc).</p>
<p>This is a much harder problem because we don’t know where to look at! If a bug is originated in task <code class="docutils literal notranslate"><span class="pre">A</span></code> it might propagate to any downstream tasks that use the product from <code class="docutils literal notranslate"><span class="pre">A</span></code> as input, this is why testing is essential. By explicitly checking our data expectations, we increase the chance of catching errors at the source, rather than in a downstream task.</p>
<p>When it happens (and trust me, it will), we recommend you to follow a recursive approach: Once you detect the error, the first question to answer is: Which task produced this output? Once you know that, start a line-by-line debugging session (post-mortem won’t work because there is no exception!), and carefully check variables to see if you can spot the error.</p>
<p>If everything looks correct, go to all upstream tasks and repeat this process. You can do this from the command line.</p>
<p>First, start an interactive session from the terminal:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">ploomber interactive</span>
</pre></div>
</div>
<p>Then debug the task that produced the buggy output:</p>
<div class="highlight-pycon notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">dag</span><span class="p">[</span><span class="s1">&#39;buggy_task&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">debug</span><span class="p">()</span>
</pre></div>
</div>
<p>If that’s not enough, check upstream tasks. To find upstream tasks, use <code class="docutils literal notranslate"><span class="pre">task.upstream</span></code>:</p>
<div class="highlight-pycon notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">dag</span><span class="p">[</span><span class="s1">&#39;buggy_task&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">upstream</span>
</pre></div>
</div>
<p>If you have a hypothesis of <em>where the error might be</em>. You can insert a breakpoint in your task’s source code to start a debugging session at any given point:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># buggy_task.py</span>

<span class="c1"># some code</span>
<span class="c1"># ...</span>
<span class="c1"># ...</span>

<span class="c1"># breakpoint: this is where I think the bug is...</span>
<span class="kn">import</span> <span class="nn">pdb</span><span class="p">;</span> <span class="n">pdb</span><span class="o">.</span><span class="n">set_trace</span><span class="p">()</span>


<span class="c1"># more code</span>
<span class="c1"># ...</span>
<span class="c1"># ...</span>
</pre></div>
</div>
<p>Then start a post-mortem session. The debugger will start at the line where you inserted the breakpoint.</p>
</section>
<section id="Using-the-CLI-to-check-if-we-fixed-the-bug">
<h2>Using the CLI to check if we fixed the bug<a class="headerlink" href="#Using-the-CLI-to-check-if-we-fixed-the-bug" title="Permalink to this headline">¶</a></h2>
<p>In a real scenario, we might try a few things before we find bug fix. To quickly iterate over candidate solutions, we’d like to check if the applied change makes our pipeline <em>not</em> to throw an error. This is where Ploomber’s incremental builds come in handy.</p>
<p>If we narrowed down the error to a specific task, we can apply changes and quickly check if the new code runs correctly by just running that task:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">ploomber task {task-name}</span>
</pre></div>
</div>
<p>If the exception happens in task <code class="docutils literal notranslate"><span class="pre">B</span></code>, but the solution has to be implemented in task <code class="docutils literal notranslate"><span class="pre">A</span></code> (where <code class="docutils literal notranslate"><span class="pre">A</span></code> is an upstream dependency of <code class="docutils literal notranslate"><span class="pre">B</span></code>), then we have to make sure that we run <code class="docutils literal notranslate"><span class="pre">A</span></code> and <code class="docutils literal notranslate"><span class="pre">B</span></code> to verify the fix. A full end-to-end run is wasteful but so is an incremental run if <code class="docutils literal notranslate"><span class="pre">B</span></code> has many downstream tasks. For testing purposes, we just care about things going well <em>until ``B``</em>. This is a good use of a partial build: it will run all tasks until it reaches a selected task (by default, it
will still skip up-to-date tasks). In our case:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">ploomber build --partially B</span>
</pre></div>
</div>
</section>
<section id="Letting-our-pipeline-fail-under-unforeseen-circumstances">
<h2>Letting our pipeline fail under unforeseen circumstances<a class="headerlink" href="#Letting-our-pipeline-fail-under-unforeseen-circumstances" title="Permalink to this headline">¶</a></h2>
<p>The error in our program is of particular interest because it posits a common scenario: our program is correct but still failed due to unforeseen circumstances (unexpected data properties). Although these bugs challenge our assumptions about input data, fixing the error is just as important as explaining <em>why</em> we fixed the way we did it.</p>
<p>Picture this: we decide to drop all observations that contain the unexpected value (<code class="docutils literal notranslate"><span class="pre">d</span></code>), now our pipeline runs correctly. A few months later, we receive new data so we run the pipeline again, but we run into the same issue because of a new unexpected value (say, <code class="docutils literal notranslate"><span class="pre">e</span></code>).</p>
<p>We could argue that one solution would be to <em>drop all unexpected values</em>. Is this the best approach? Dropping observations silently is dangerous, as they might contain helpful information for our analysis. If we bury a <code class="docutils literal notranslate"><span class="pre">drop=True</span></code> piece of code in a pipeline with dozens of files, we will cause <em>a lot of</em> trouble to someone (which could be us) in the future. As we mentioned in the previous guide: explicitly stating our data expectations is the way to move forward.</p>
<p>If we decide dropping <code class="docutils literal notranslate"><span class="pre">d</span></code> is a reasonable choice, we can encode our new data expectations in the upstream task testing function (because that’s the task that supplies input data). Let’s recall how our pipeline looks like:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="c1"># Content of pipeline.yaml</span><span class="w"></span>
<span class="nt">tasks</span><span class="p">:</span><span class="w"></span>
<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">source</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">load.py</span><span class="w"></span>
<span class="w">    </span><span class="nt">product</span><span class="p">:</span><span class="w"></span>
<span class="w">      </span><span class="nt">nb</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">output/raw.html</span><span class="w"></span>
<span class="w">      </span><span class="nt">train</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">output/train.csv</span><span class="w"></span>
<span class="w">      </span><span class="nt">test</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">output/test.csv</span><span class="w"></span>

<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">source</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">preprocess.py</span><span class="w"></span>
<span class="w">    </span><span class="nt">product</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">output/clean.html</span><span class="w"></span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">load</span></code> supplies input for <code class="docutils literal notranslate"><span class="pre">preprocess</span></code>. Our testing function for the <code class="docutils literal notranslate"><span class="pre">load</span></code> task would look like this:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">test_load</span><span class="p">(</span><span class="n">product</span><span class="p">):</span>
    <span class="n">train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">product</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">]))</span>
    <span class="n">test</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">product</span><span class="p">[</span><span class="s1">&#39;test&#39;</span><span class="p">]))</span>

    <span class="c1"># NOTE: these are the expected values in the cat column</span>
    <span class="c1"># we expect value &#39;d&#39; in the testing set and we&#39;ll</span>
    <span class="c1"># drop it during preprocessing. Any other unexpected</span>
    <span class="c1"># values will raise an exception here so we have the</span>
    <span class="c1"># chance to decide what to do with it</span>
    <span class="k">assert</span> <span class="nb">set</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="s1">&#39;cat&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">())</span> <span class="o">==</span> <span class="p">{</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="s1">&#39;c&#39;</span><span class="p">}</span>
    <span class="k">assert</span> <span class="nb">set</span><span class="p">(</span><span class="n">test</span><span class="p">[</span><span class="s1">&#39;cat&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">())</span> <span class="o">==</span> <span class="p">{</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="s1">&#39;c&#39;</span><span class="p">,</span> <span class="s1">&#39;d&#39;</span><span class="p">}</span>
</pre></div>
</div>
<p>The comment should actually be part of the testing function, without it, there is no context to understand why are we testing such a specific condition.</p>
</section>
<section id="Debugging-(templated)-SQL-scripts">
<h2>Debugging (templated) SQL scripts<a class="headerlink" href="#Debugging-(templated)-SQL-scripts" title="Permalink to this headline">¶</a></h2>
<p>So far, we’ve discussed how to debug Python scripts, but SQL scripts can also fail. In a previous guide, we showed how templated SQL scripts help us write more concise SQL code, but this comes with a cost. Relying too much on templating makes our templated source code short but hard to read. If your database complains about syntax errors when executing SQL tasks, chances are, the errors is coming from incorrect templating logic. One good first debugging step is to take a look at the rendered
code. You can do so from the command line:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">ploomber task {task-name} --source</span>
</pre></div>
</div>
<p>Apart from looking at rendered code, there isn’t much to say about debugging SQL scripts because there are no interactive debuggers. The best we can do is to organize our scripts in a clear way to make it easy to spot errors.</p>
</section>
<section id="Where-to-go-next">
<h2>Where to go next<a class="headerlink" href="#Where-to-go-next" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://docs.python.org/3/library/pdb.html">pdb documentation</a></p></li>
</ul>
</section>
</section>


                            <div class="clearer"></div>
                        </div>
                    </div>
                </div>
                <div class="clearer"></div>
            </div>
        </div>
        <div class="d-none d-xl-block col-xl-2 third-column">
            
<div class="sphinxsidebar" role="navigation" aria-label="main navigation">
    <div class="sphinxsidebarwrapper">
<ul>
<li><a class="reference internal" href="#">Debugging</a><ul>
<li><a class="reference internal" href="#Why-debugging-pipelines-is-hard">Why debugging pipelines is hard</a></li>
<li><a class="reference internal" href="#Debugger-basics">Debugger basics</a></li>
<li><a class="reference internal" href="#Tales-of-a-buggy-pipeline">Tales of a buggy pipeline</a></li>
<li><a class="reference internal" href="#Starting-line-by-line-debugging-sessions">Starting line-by-line debugging sessions</a></li>
<li><a class="reference internal" href="#Post-mortem-debugging">Post-mortem debugging</a></li>
<li><a class="reference internal" href="#More-difficult-scenario:-no-exceptions-raised-but-wrong-output">More difficult scenario: no exceptions raised but wrong output</a></li>
<li><a class="reference internal" href="#Using-the-CLI-to-check-if-we-fixed-the-bug">Using the CLI to check if we fixed the bug</a></li>
<li><a class="reference internal" href="#Letting-our-pipeline-fail-under-unforeseen-circumstances">Letting our pipeline fail under unforeseen circumstances</a></li>
<li><a class="reference internal" href="#Debugging-(templated)-SQL-scripts">Debugging (templated) SQL scripts</a></li>
<li><a class="reference internal" href="#Where-to-go-next">Where to go next</a></li>
</ul>
</li>
</ul>

    </div>
</div>
        </div>
    </div>
</div>


<script src="https://cdn.jsdelivr.net/npm/@docsearch/js@3"></script>

<script type="text/javascript">
    docsearch({
        appId: 'Y6L7HQ2HZO',
        apiKey: 'a44b754f3d890a27dcbd9b4f860fea6b',
        indexName: 'ploomber',
        container: '#search',
        debug: false

    });
</script>
<div class="footer" role="contentinfo">
</div>
  </body>
</html>